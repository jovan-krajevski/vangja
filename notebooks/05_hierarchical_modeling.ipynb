{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5161a619",
   "metadata": {},
   "source": [
    "# Chapter 05: Hierarchical Modeling with Partial Pooling\n",
    "\n",
    "This notebook demonstrates one of vangja's most powerful features: **hierarchical Bayesian modeling** with partial pooling. This is inspired by:\n",
    "\n",
    "- The [timeseers](https://github.com/MBrouns/timeseers) library, which extends Facebook Prophet with hierarchical modeling capabilities\n",
    "- Matthijs Brouns' **PyMCon 2020** talk: [*Forecasting Hierarchical Time Series*](https://www.youtube.com/watch?v=appLxcMLT9Y)\n",
    "- Matthijs Brouns' **PyData** talk: [*Hierarchical Time Series Forecasting*](https://www.youtube.com/watch?v=jo12CWZ00Lo)\n",
    "\n",
    "## Why Hierarchical Modeling?\n",
    "\n",
    "When forecasting multiple related time series, we often face a trade-off:\n",
    "\n",
    "1. **Complete pooling** (`pool_type=\"complete\"`): All series share the same parameters. This is useful when series are very similar, but ignores individual differences.\n",
    "\n",
    "2. **No pooling** (`pool_type=\"individual\"`): Each series has independent parameters. This captures individual differences, but doesn't leverage shared patterns and can overfit with limited data.\n",
    "\n",
    "3. **Partial pooling** (`pool_type=\"partial\"`): Parameters are drawn from a shared distribution (hyperprior). This allows series to \"borrow strength\" from each other while still capturing individual differences.\n",
    "\n",
    "**Partial pooling is especially valuable when:**\n",
    "- Some series have limited data or gaps\n",
    "- Series belong to natural groups (e.g., stores in regions, products in categories)\n",
    "- You want to share seasonal patterns while allowing different trends\n",
    "\n",
    "## In This Notebook\n",
    "\n",
    "We'll generate synthetic data representing multiple \"product\" time series with **random gaps** in the data, belonging to two seasonal groups (\"summer\" and \"winter\" products), plus an \"all-year\" product with minimal seasonality. We then compare:\n",
    "\n",
    "- **Individual fitting** — Each series learns its own seasonality independently\n",
    "- **Partial pooling** — Series share seasonal information hierarchically\n",
    "\n",
    "The key insight is **not** in the aggregate metrics, but in **what happens inside the gaps**. Individual fitting tends to produce random, incorrect seasonal patterns in the missing intervals, while partial pooling leverages information from all series — including the all-year product — to produce coherent seasonal predictions even where data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc5ea5",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vangja import LinearTrend, FourierSeasonality\n",
    "from vangja.datasets import generate_hierarchical_products\n",
    "from vangja.utils import metrics, remove_random_gaps\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158e979",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "We'll use synthetic time series data representing sales for different products, inspired by the [timeseers](https://github.com/MBrouns/timeseers) library. The key insight is that products within the same \"group\" share similar seasonal patterns:\n",
    "\n",
    "- **Summer products** (3 series): Peak in summer months (positive yearly seasonality)\n",
    "- **Winter products** (2 series): Peak in winter months (opposite yearly seasonality)\n",
    "- **All-year products** (1 series): Minimal yearly seasonality\n",
    "\n",
    "This scenario is ideal for hierarchical modeling: products within a group share seasonal patterns, but each product has its own trend and noise level.\n",
    "\n",
    "We generate clean data using `generate_hierarchical_products()` and then introduce random gaps using `remove_random_gaps()` for each product except the `all_year` product. This simulates a real-world scenario where data collection may be interrupted — and more importantly, it lets us see how each modeling approach handles the missing intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean hierarchical product data with all 6 series (including all_year)\n",
    "df_full, product_params = generate_hierarchical_products(seed=42, include_all_year=True)\n",
    "\n",
    "# Apply random gaps to every series except all_year\n",
    "np.random.seed(42)\n",
    "df_parts = []\n",
    "for name, params in product_params.items():\n",
    "    series_data = df_full[df_full[\"series\"] == name].copy()\n",
    "    if params[\"group\"] != \"all_year\":\n",
    "        series_data = remove_random_gaps(series_data, n_gaps=4, gap_fraction=0.2)\n",
    "    df_parts.append(series_data)\n",
    "\n",
    "df = pd.concat(df_parts, ignore_index=True)\n",
    "\n",
    "print(f\"Date range: {df['ds'].min().date()} to {df['ds'].max().date()}\")\n",
    "print(f\"Number of products: {len(product_params)}\")\n",
    "print(\n",
    "    f\"Summer products: {[k for k, v in product_params.items() if v['group'] == 'summer']}\"\n",
    ")\n",
    "print(\n",
    "    f\"Winter products: {[k for k, v in product_params.items() if v['group'] == 'winter']}\"\n",
    ")\n",
    "print(\n",
    "    f\"All-year products: {[k for k, v in product_params.items() if v['group'] == 'all_year']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all series in a single plot with colors by group\n",
    "# Using scatter plot to handle gaps in data (missing intervals)\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "# Define colors by group\n",
    "group_colors = {\"summer\": \"tab:orange\", \"winter\": \"tab:blue\", \"all_year\": \"tab:green\"}\n",
    "\n",
    "for name, params in product_params.items():\n",
    "    series_data = df[df[\"series\"] == name]\n",
    "    color = group_colors[params[\"group\"]]\n",
    "    ax.scatter(\n",
    "        series_data[\"ds\"],\n",
    "        series_data[\"y\"],\n",
    "        s=1,\n",
    "        alpha=0.7,\n",
    "        color=color,\n",
    "        label=f\"{name} ({params['group']})\",\n",
    "    )\n",
    "\n",
    "ax.set_title(\"All Product Series by Group\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Sales\")\n",
    "ax.legend(loc=\"upper left\", fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print y-ranges and data availability for each series\n",
    "for name, params in product_params.items():\n",
    "    series_data = df[df[\"series\"] == name]\n",
    "    print(\n",
    "        f\"{name}: y range = [{series_data['y'].min():.0f}, {series_data['y'].max():.0f}], \"\n",
    "        f\"n_points = {len(series_data)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ecb7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Approach 1: Individual Fitting (No Pooling)\n",
    "\n",
    "First, let's fit each series independently using `pool_type=\"individual\"`. Each series gets its own:\n",
    "- Trend parameters (slope, intercept)\n",
    "- Changepoint deltas (via `delta_pool_type=\"individual\"`)\n",
    "- Seasonality coefficients\n",
    "- Observation noise (via `sigma_pool_type=\"individual\"`)\n",
    "\n",
    "Since each series is fit independently, the model can learn arbitrary seasonality patterns for each series. With gaps in the data, the model has to infer what happens in those intervals purely from its own limited observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with individual pooling (no information sharing)\n",
    "# Each series gets its own parameters including observation noise\n",
    "model_individual = (\n",
    "    LinearTrend(n_changepoints=10, pool_type=\"individual\", delta_pool_type=\"individual\")\n",
    "    + FourierSeasonality(period=365.25, series_order=5, pool_type=\"individual\")\n",
    "    + FourierSeasonality(period=7, series_order=2, pool_type=\"individual\")\n",
    ")\n",
    "\n",
    "print(f\"Model: {model_individual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f647c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the individual model with sigma_pool_type=\"individual\"\n",
    "# This allows each series to have its own observation noise level\n",
    "start_time = time.time()\n",
    "model_individual.fit(\n",
    "    df, method=\"mapx\", scale_mode=\"individual\", sigma_pool_type=\"individual\"\n",
    ")\n",
    "time_individual = time.time() - start_time\n",
    "\n",
    "print(f\"Individual fitting time: {time_individual:.2f}s\")\n",
    "print(f\"Group mapping: {model_individual.groups_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1380c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fitted values (predictions on training dates)\n",
    "fitted_individual = model_individual.predict(horizon=0, freq=\"D\")\n",
    "\n",
    "# Calculate metrics for each series on the full dataset\n",
    "individual_metrics = []\n",
    "for name in product_params.keys():\n",
    "    group_code = [k for k, v in model_individual.groups_.items() if v == name][0]\n",
    "    series_data = df[df[\"series\"] == name]\n",
    "    fitted_for_metrics = fitted_individual[[\"ds\", f\"yhat_{group_code}\"]].copy()\n",
    "    fitted_for_metrics.columns = [\"ds\", \"yhat_0\"]\n",
    "    m = metrics(series_data, fitted_for_metrics, \"complete\")\n",
    "    m.index = [name]\n",
    "    individual_metrics.append(m)\n",
    "\n",
    "individual_metrics_df = pd.concat(individual_metrics)\n",
    "print(\"Individual Fitting Metrics (in-sample):\")\n",
    "display(individual_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2e297",
   "metadata": {},
   "source": [
    "### What happens in the gaps?\n",
    "\n",
    "The aggregate in-sample metrics above look reasonable, but they only measure fit quality **where we have data**. The real question is: **what does the model predict in the gaps where data is missing?**\n",
    "\n",
    "When fitting individually, each series learns its yearly seasonal pattern from its own incomplete observations. With large gaps (20% of data removed, 4 times), the model may learn a yearly seasonality that is random and wrong — it fills in the gaps with whatever pattern fits the sparse data best, which can lead to erratic seasonal effects in the missing intervals.\n",
    "\n",
    "Let's use the built-in `plot()` method to examine the individual model's predictions, paying close attention to the intervals where data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual model predictions for winter_2\n",
    "# The y_true overlaid in orange shows where actual data exists;\n",
    "# look at the gaps to see what the model \"imagines\" without data.\n",
    "model_individual.plot(\n",
    "    fitted_individual, series=\"winter_2\", y_true=df[df[\"series\"] == \"winter_2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c10e41",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Approach 2: Partial Pooling (Hierarchical)\n",
    "\n",
    "Now let's use partial pooling with `pool_type=\"partial\"`. In this approach:\n",
    "\n",
    "- **Trend**: Each series has its own slope and intercept, but they're drawn from a shared distribution. This allows series to \"borrow strength\" from each other.\n",
    "- **Changepoint Deltas**: We use `delta_pool_type=\"partial\"` to also share changepoint information hierarchically.\n",
    "- **Seasonality**: The Fourier coefficients are partially pooled with high `shrinkage_strength`, allowing series to strongly share seasonal patterns while still permitting individual variations.\n",
    "\n",
    "The hierarchical structure is:\n",
    "```\n",
    "slope_shared ~ Normal(0, σ_slope)\n",
    "slope[i] ~ Normal(slope_shared, σ_individual)\n",
    "```\n",
    "\n",
    "Crucially, **partial pooling shares seasonal information across all series**, including the `all_year` product which has complete data and minimal (but real) yearly seasonality. This means that even in the gaps of other series, the model can draw on the shared seasonal knowledge to produce coherent predictions — rather than inventing arbitrary patterns from sparse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f056d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with partial pooling (hierarchical)\n",
    "# High shrinkage_strength on seasonality forces strong sharing of seasonal patterns\n",
    "model_partial = (\n",
    "    LinearTrend(\n",
    "        n_changepoints=10,\n",
    "        pool_type=\"partial\",\n",
    "        delta_pool_type=\"partial\",\n",
    "        shrinkage_strength=10,\n",
    "    )\n",
    "    + FourierSeasonality(\n",
    "        period=365.25, series_order=5, pool_type=\"partial\", shrinkage_strength=1000\n",
    "    )\n",
    "    + FourierSeasonality(\n",
    "        period=7, series_order=2, pool_type=\"partial\", shrinkage_strength=1000\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Model: {model_partial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the partial pooling model\n",
    "start_time = time.time()\n",
    "model_partial.fit(\n",
    "    df, method=\"mapx\", scale_mode=\"individual\", sigma_pool_type=\"individual\"\n",
    ")\n",
    "time_partial = time.time() - start_time\n",
    "\n",
    "print(f\"Partial pooling fitting time: {time_partial:.2f}s\")\n",
    "print(f\"Group mapping: {model_partial.groups_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ff767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "future_partial = model_partial.predict(horizon=0, freq=\"D\")\n",
    "\n",
    "# Calculate metrics for each series\n",
    "partial_metrics = []\n",
    "for name in product_params.keys():\n",
    "    group_code = [k for k, v in model_partial.groups_.items() if v == name][0]\n",
    "    test_series = df[df[\"series\"] == name]\n",
    "    future_for_metrics = future_partial[[\"ds\", f\"yhat_{group_code}\"]].copy()\n",
    "    future_for_metrics.columns = [\"ds\", \"yhat_0\"]\n",
    "    m = metrics(test_series, future_for_metrics, \"complete\")\n",
    "    m.index = [name]\n",
    "    partial_metrics.append(m)\n",
    "\n",
    "partial_metrics_df = pd.concat(partial_metrics)\n",
    "print(\"Partial Pooling Metrics:\")\n",
    "display(partial_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b62f61f",
   "metadata": {},
   "source": [
    "### How partial pooling handles the gaps\n",
    "\n",
    "Now compare the partial pooling model's predictions for the same series. Because the hierarchical model shares seasonal information across all 6 series — including the `all_year` product which has **no gaps** and a well-defined (albeit minimal) yearly pattern — the model is able to produce coherent seasonal predictions even in the missing intervals.\n",
    "\n",
    "The `all_year` product acts as an anchor: its complete data coverage teaches the shared seasonal hyperprior about the overall yearly cycle. This information flows hierarchically to the winter and summer products, resulting in smoother and more realistic seasonal patterns in the gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot partial pooling predictions for winter_2\n",
    "# Compare this to the individual model's plot above — notice how\n",
    "# the seasonal pattern in the gaps is smoother and more consistent.\n",
    "model_partial.plot(\n",
    "    future_partial, series=\"winter_2\", y_true=df[df[\"series\"] == \"winter_2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4769b6f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A Note on Complete Pooling\n",
    "\n",
    "We do not demonstrate complete pooling (`pool_type=\"complete\"`) in this notebook because it is rarely appropriate for series with different scales and opposite seasonality patterns. When all series share a single set of parameters, the model is forced to find a single compromise that fits no series well.\n",
    "\n",
    "**However, complete pooling can be useful when:**\n",
    "\n",
    "- All series are very similar in scale, trend, and seasonality (e.g., replicate measurements of the same process)\n",
    "- You intentionally want a single \"average\" forecast across all series\n",
    "- You have very little data per series and need maximum regularization\n",
    "- You are building a baseline to compare against more flexible approaches\n",
    "\n",
    "In our product dataset, complete pooling would try to learn one seasonal pattern for both summer and winter products — an impossible compromise that would produce poor predictions for all series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71482c9f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparison of Approaches\n",
    "\n",
    "Let's compare individual and partial pooling side by side. Note that the **metrics alone do not tell the full story** — both approaches may show similar in-sample fit quality where data exists. The crucial difference is in the gap regions, which the metrics cannot capture since there is no ground truth there.\n",
    "\n",
    "The comparison table below shows in-sample metrics, followed by a visual comparison of predictions for all series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_rows = []\n",
    "\n",
    "for name in product_params.keys():\n",
    "    comparison_rows.append(\n",
    "        {\n",
    "            \"Series\": name,\n",
    "            \"Group\": product_params[name][\"group\"],\n",
    "            \"Approach\": \"Individual\",\n",
    "            \"RMSE\": individual_metrics_df.loc[name, \"rmse\"],\n",
    "            \"MAE\": individual_metrics_df.loc[name, \"mae\"],\n",
    "            \"MAPE\": individual_metrics_df.loc[name, \"mape\"],\n",
    "        }\n",
    "    )\n",
    "    comparison_rows.append(\n",
    "        {\n",
    "            \"Series\": name,\n",
    "            \"Group\": product_params[name][\"group\"],\n",
    "            \"Approach\": \"Partial\",\n",
    "            \"RMSE\": partial_metrics_df.loc[name, \"rmse\"],\n",
    "            \"MAE\": partial_metrics_df.loc[name, \"mae\"],\n",
    "            \"MAPE\": partial_metrics_df.loc[name, \"mape\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_rows)\n",
    "print(\"Full Comparison:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2094d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by approach\n",
    "summary = (\n",
    "    comparison_df.groupby(\"Approach\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"RMSE\": [\"mean\", \"std\"],\n",
    "            \"MAE\": [\"mean\", \"std\"],\n",
    "            \"MAPE\": [\"mean\", \"std\"],\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(\"Summary Statistics by Approach:\")\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing comparison\n",
    "timing_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Approach\": [\"Individual\", \"Partial\"],\n",
    "        \"Time (s)\": [time_individual, time_partial],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Timing Comparison:\")\n",
    "display(timing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions for each series (2 per row for better readability)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, params) in enumerate(product_params.items()):\n",
    "    ax = axes[i]\n",
    "    train_series = df[df[\"series\"] == name]\n",
    "\n",
    "    # Get predictions\n",
    "    ind_group = [k for k, v in model_individual.groups_.items() if v == name][0]\n",
    "    par_group = [k for k, v in model_partial.groups_.items() if v == name][0]\n",
    "\n",
    "    # Plot training data\n",
    "    ax.plot(\n",
    "        train_series[\"ds\"],\n",
    "        train_series[\"y\"],\n",
    "        \"b.\",\n",
    "        markersize=0.5,\n",
    "        alpha=0.3,\n",
    "        label=\"Training\",\n",
    "    )\n",
    "    # Plot predictions\n",
    "    ax.plot(\n",
    "        fitted_individual[\"ds\"],\n",
    "        fitted_individual[f\"yhat_{ind_group}\"],\n",
    "        \"r-\",\n",
    "        linewidth=1.5,\n",
    "        alpha=0.8,\n",
    "        label=\"Individual\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        future_partial[\"ds\"],\n",
    "        future_partial[f\"yhat_{par_group}\"],\n",
    "        \"m--\",\n",
    "        linewidth=1.5,\n",
    "        alpha=0.8,\n",
    "        label=\"Partial\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{name} ({params['group']})\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Sales\")\n",
    "    ax.legend(loc=\"upper left\", fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6e646",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### Why Metrics Aren't Everything\n",
    "\n",
    "In-sample metrics (RMSE, MAE, MAPE) measure how well the model fits the **observed** data points. But when data has gaps, the real value of hierarchical modeling is in how the model fills those gaps. Individual fitting can produce arbitrarily wrong seasonal patterns in missing intervals because it has no external information to constrain the predictions. Partial pooling regularizes these predictions by sharing seasonal knowledge across series.\n",
    "\n",
    "### Pool Types in Vangja\n",
    "\n",
    "| Pool Type | Description | Use Case |\n",
    "|-----------|-------------|----------|\n",
    "| `\"complete\"` | All series share parameters | Very similar series, single pattern to learn |\n",
    "| `\"individual\"` | Each series has independent parameters | Unrelated series, sufficient data per series |\n",
    "| `\"partial\"` | Hierarchical with shared hyperpriors | Related series, want to borrow strength |\n",
    "\n",
    "### Key Pooling Parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `pool_type` | Main pooling for trend/seasonality parameters |\n",
    "| `delta_pool_type` | Pooling for changepoint deltas (use with `pool_type=\"partial\"`) |\n",
    "| `sigma_pool_type` | Pooling for observation noise (pass to `fit()`) |\n",
    "| `shrinkage_strength` | How strongly series are pulled toward shared mean (higher = more pooling) |\n",
    "\n",
    "### When to Use Partial Pooling\n",
    "\n",
    "**Use partial pooling when:**\n",
    "- Series belong to natural groups (products, stores, regions)\n",
    "- Some series have limited data or gaps in coverage\n",
    "- You expect shared patterns across series (e.g., common seasonality)\n",
    "- You want coherent predictions in missing-data intervals\n",
    "\n",
    "**Avoid partial pooling when:**\n",
    "- Series are truly independent with no shared patterns\n",
    "- Each series has abundant, complete data for reliable estimation\n",
    "- Computational speed is critical (partial pooling adds complexity)\n",
    "\n",
    "### Next: Caveats of Hierarchical Modeling\n",
    "\n",
    "In the next chapter, we explore two important caveats:\n",
    "\n",
    "1. **Shrinkage strength is a hyperparameter** that must be tuned — different values produce meaningfully different results\n",
    "2. **Opposite seasonality** (summer vs winter products) interacts with shrinkage in subtle ways, and the `UniformConstant(-1, 1)` trick from timeseers can help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f4efe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vangja20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
