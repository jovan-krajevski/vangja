{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83006d24",
   "metadata": {},
   "source": [
    "# Chapter 02: Inference Algorithms\n",
    "\n",
    "This notebook explores the different Bayesian inference algorithms available in vangja. We'll use the multiplicative model from the Air Passengers dataset to compare:\n",
    "\n",
    "1. **Maximum A Posteriori (MAP)** - Point estimates\n",
    "2. **Variational Inference (ADVI)** - Approximate posterior\n",
    "3. **Markov Chain Monte Carlo (NUTS)** - Full posterior sampling\n",
    "\n",
    "Each method offers different trade-offs between computational speed and the richness of uncertainty quantification.\n",
    "\n",
    "> **Reference**: For a detailed exploration of these Bayesian inference techniques in time series forecasting, see Krajevski & Tojtovska Ribarski (2026): [*Going NUTS with ADVI: Exploring various Bayesian Inference techniques with Facebook Prophet*](https://arxiv.org/abs/2601.20120), arXiv:2601.20120."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc386c",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe018d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vangja import LinearTrend, FourierSeasonality\n",
    "from vangja.datasets import load_air_passengers\n",
    "from vangja.utils import metrics\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59314f8d",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "We'll use the same Air Passengers dataset from the Getting Started notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12247007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Air Passengers dataset from vangja.datasets\n",
    "air_passengers = load_air_passengers()\n",
    "\n",
    "# Split data: use last 12 months for testing\n",
    "train = air_passengers[:-12].copy()\n",
    "test = air_passengers[-12:].copy()\n",
    "\n",
    "print(f\"Training set: {train['ds'].min()} to {train['ds'].max()} ({len(train)} samples)\")\n",
    "print(f\"Test set: {test['ds'].min()} to {test['ds'].max()} ({len(test)} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be4e59",
   "metadata": {},
   "source": [
    "## Define the Multiplicative Model\n",
    "\n",
    "We'll use a multiplicative model that captures the increasing variance with trend:\n",
    "\n",
    "$$y(t) = g(t) \\cdot (1 + s(t)) + \\epsilon$$\n",
    "\n",
    "where $g(t)$ is the linear trend and $s(t)$ is the combined seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658fbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create a fresh multiplicative model instance.\"\"\"\n",
    "    return LinearTrend(n_changepoints=25) ** (\n",
    "        FourierSeasonality(period=365.25, series_order=10)\n",
    "        + FourierSeasonality(period=7, series_order=3)\n",
    "    )\n",
    "\n",
    "print(f\"Model structure: {create_model()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7d165",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Maximum A Posteriori (MAP) Estimation\n",
    "\n",
    "### What is MAP?\n",
    "\n",
    "Maximum A Posteriori (MAP) estimation finds the **single most probable parameter values** given the data and priors. Mathematically, MAP finds:\n",
    "\n",
    "$$\\hat{\\theta}_{MAP} = \\arg\\max_{\\theta} P(\\theta | D) = \\arg\\max_{\\theta} P(D | \\theta) \\cdot P(\\theta)$$\n",
    "\n",
    "where $P(D | \\theta)$ is the likelihood and $P(\\theta)$ is the prior.\n",
    "\n",
    "**Advantages:**\n",
    "- Very fast computation\n",
    "- Good for quick prototyping and model comparison\n",
    "- Works well when you have enough data\n",
    "\n",
    "**Limitations:**\n",
    "- Provides only a point estimate (no uncertainty quantification)\n",
    "- Can get stuck in local optima\n",
    "- Doesn't capture the full shape of the posterior distribution\n",
    "\n",
    "### PyMC's `map` vs pymc-extras' `mapx`\n",
    "\n",
    "Vangja supports two MAP implementations:\n",
    "\n",
    "| Feature | `map` (PyMC) | `mapx` (pymc-extras) |\n",
    "|---------|--------------|----------------------|\n",
    "| Backend | SciPy optimizers | JAX-based optimization |\n",
    "| Speed | Slower | **Significantly faster** |\n",
    "| Gradient computation | Numerical or PyTensor | JAX autodiff |\n",
    "| Recommended | Legacy support | **Default choice** |\n",
    "\n",
    "The `mapx` method from pymc-extras uses JAX for automatic differentiation, resulting in much faster optimization, especially for models with many parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82de8a0",
   "metadata": {},
   "source": [
    "### 1.1 MAP with `mapx` (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618901a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model using mapx (default)\n",
    "model_mapx = create_model()\n",
    "\n",
    "start_time = time.time()\n",
    "model_mapx.fit(train, method=\"mapx\")\n",
    "mapx_time = time.time() - start_time\n",
    "\n",
    "print(f\"MAPX fitting time: {mapx_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate\n",
    "future_mapx = model_mapx.predict(horizon=365, freq=\"D\")\n",
    "metrics_mapx = metrics(test, future_mapx, \"complete\")\n",
    "\n",
    "print(\"MAPX Metrics:\")\n",
    "display(metrics_mapx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec12fe",
   "metadata": {},
   "source": [
    "### 1.2 MAP with `map` (Standard PyMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e261604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model using standard PyMC map\n",
    "model_map = create_model()\n",
    "\n",
    "start_time = time.time()\n",
    "model_map.fit(train, method=\"map\")\n",
    "map_time = time.time() - start_time\n",
    "\n",
    "print(f\"MAP fitting time: {map_time:.2f} seconds\")\n",
    "print(f\"Speedup with mapx: {map_time / mapx_time:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7230109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate\n",
    "future_map = model_map.predict(horizon=365, freq=\"D\")\n",
    "metrics_map = metrics(test, future_map, \"complete\")\n",
    "\n",
    "print(\"MAP Metrics:\")\n",
    "display(metrics_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ed7df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Variational Inference (ADVI)\n",
    "\n",
    "### What is Variational Inference?\n",
    "\n",
    "Variational Inference (VI) approximates the true posterior distribution $P(\\theta | D)$ with a simpler distribution $Q(\\theta)$ from a tractable family. The goal is to minimize the **Kullback-Leibler (KL) divergence** between $Q$ and the true posterior:\n",
    "\n",
    "$$Q^* = \\arg\\min_Q KL(Q(\\theta) || P(\\theta | D))$$\n",
    "\n",
    "### Automatic Differentiation Variational Inference (ADVI)\n",
    "\n",
    "ADVI is a specific VI algorithm that:\n",
    "1. Transforms all parameters to unconstrained space\n",
    "2. Approximates the posterior with a multivariate Gaussian\n",
    "3. Uses gradient-based optimization to find the best approximation\n",
    "\n",
    "**Advantages:**\n",
    "- Much faster than MCMC\n",
    "- Provides uncertainty estimates (unlike MAP)\n",
    "- Scales well to large datasets\n",
    "\n",
    "**Limitations:**\n",
    "- Approximation may miss multimodal posteriors\n",
    "- Gaussian assumption may be too restrictive\n",
    "- Can underestimate uncertainty\n",
    "\n",
    "### Variants\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `advi` | Mean-field approximation (diagonal covariance) |\n",
    "| `fullrank_advi` | Full covariance matrix (captures correlations) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11298bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model using ADVI\n",
    "model_advi = create_model()\n",
    "\n",
    "start_time = time.time()\n",
    "model_advi.fit(train, method=\"advi\", samples=1000, progressbar=True)\n",
    "advi_time = time.time() - start_time\n",
    "\n",
    "print(f\"ADVI fitting time: {advi_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279546d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate\n",
    "future_advi = model_advi.predict(horizon=365, freq=\"D\")\n",
    "metrics_advi = metrics(test, future_advi, \"complete\")\n",
    "\n",
    "print(\"ADVI Metrics:\")\n",
    "display(metrics_advi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b6ae0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Markov Chain Monte Carlo (NUTS)\n",
    "\n",
    "### What is MCMC?\n",
    "\n",
    "Markov Chain Monte Carlo (MCMC) methods generate samples from the posterior distribution by constructing a Markov chain that has the posterior as its stationary distribution. After enough iterations, the samples approximate the true posterior.\n",
    "\n",
    "### No-U-Turn Sampler (NUTS)\n",
    "\n",
    "NUTS is an advanced MCMC algorithm that:\n",
    "1. Uses Hamiltonian dynamics to propose distant moves\n",
    "2. Automatically tunes the trajectory length (no manual tuning needed)\n",
    "3. Avoids random walk behavior, leading to efficient exploration\n",
    "\n",
    "**Advantages:**\n",
    "- Provides the **gold standard** for posterior inference\n",
    "- Captures the full posterior distribution, including multimodality\n",
    "- Accurate uncertainty quantification\n",
    "- Diagnostic tools available (R-hat, ESS, divergences)\n",
    "\n",
    "**Limitations:**\n",
    "- Computationally expensive\n",
    "- Requires tuning (warmup/burn-in period)\n",
    "- May have convergence issues for complex models\n",
    "\n",
    "### Sampler Backends\n",
    "\n",
    "Vangja supports multiple NUTS backends:\n",
    "\n",
    "| Backend | Description |\n",
    "|---------|-------------|\n",
    "| `pymc` | Default PyMC sampler |\n",
    "| `nutpie` | Fast Rust-based sampler |\n",
    "| `numpyro` | JAX-based sampler (GPU support) |\n",
    "| `blackjax` | JAX-based sampler |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df19434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model using NUTS\n",
    "# Using fewer samples for demonstration (increase for production)\n",
    "model_nuts = create_model()\n",
    "\n",
    "start_time = time.time()\n",
    "model_nuts.fit(\n",
    "    train,\n",
    "    method=\"nuts\",\n",
    "    samples=1000,     # Number of posterior samples per chain\n",
    "    chains=4,         # Number of independent chains\n",
    "    cores=4,          # Parallel cores to use\n",
    "    progressbar=True\n",
    ")\n",
    "nuts_time = time.time() - start_time\n",
    "\n",
    "print(f\"NUTS fitting time: {nuts_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f49056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate\n",
    "future_nuts = model_nuts.predict(horizon=365, freq=\"D\")\n",
    "metrics_nuts = metrics(test, future_nuts, \"complete\")\n",
    "\n",
    "print(\"NUTS Metrics:\")\n",
    "display(metrics_nuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b257e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparison of Results\n",
    "\n",
    "Let's compare all inference methods side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84fe82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all metrics\n",
    "comparison = pd.DataFrame({\n",
    "    \"Method\": [\"MAPX\", \"MAP\", \"ADVI\", \"NUTS\"],\n",
    "    \"Time (s)\": [mapx_time, map_time, advi_time, nuts_time],\n",
    "    \"RMSE\": [\n",
    "        metrics_mapx[\"rmse\"].values[0],\n",
    "        metrics_map[\"rmse\"].values[0],\n",
    "        metrics_advi[\"rmse\"].values[0],\n",
    "        metrics_nuts[\"rmse\"].values[0]\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        metrics_mapx[\"mae\"].values[0],\n",
    "        metrics_map[\"mae\"].values[0],\n",
    "        metrics_advi[\"mae\"].values[0],\n",
    "        metrics_nuts[\"mae\"].values[0]\n",
    "    ],\n",
    "    \"MAPE\": [\n",
    "        metrics_mapx[\"mape\"].values[0],\n",
    "        metrics_map[\"mape\"].values[0],\n",
    "        metrics_advi[\"mape\"].values[0],\n",
    "        metrics_nuts[\"mape\"].values[0]\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nComparison of Inference Methods:\")\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd470d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison of predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "methods = [\n",
    "    (\"MAPX\", future_mapx),\n",
    "    (\"MAP\", future_map),\n",
    "    (\"ADVI\", future_advi),\n",
    "    (\"NUTS\", future_nuts)\n",
    "]\n",
    "\n",
    "for ax, (name, future) in zip(axes.flat, methods):\n",
    "    ax.plot(train[\"ds\"], train[\"y\"], \"b.\", label=\"Training data\", markersize=3)\n",
    "    ax.plot(test[\"ds\"], test[\"y\"], \"g.\", label=\"Test data\", markersize=5)\n",
    "    ax.plot(future[\"ds\"], future[\"yhat_0\"], \"r-\", label=\"Prediction\", linewidth=1)\n",
    "    ax.set_title(f\"{name} - Multiplicative Model\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Number of Passengers\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1463e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Choosing an Inference Method\n",
    "\n",
    "| Method | Speed | Uncertainty | Best For |\n",
    "|--------|-------|-------------|----------|\n",
    "| **MAPX** | ⚡⚡⚡ Fastest | ❌ None | Quick prototyping, model selection, production with large data |\n",
    "| **MAP** | ⚡⚡ Fast | ❌ None | Legacy compatibility |\n",
    "| **ADVI** | ⚡⚡ Fast | ✅ Approximate | When you need uncertainty but MCMC is too slow |\n",
    "| **NUTS** | ⚡ Slow | ✅✅ Full | Research, when accuracy matters most, small to medium data |\n",
    "\n",
    "### Transfer Learning Consideration\n",
    "\n",
    "When using vangja's transfer learning capabilities (fitting short time series with priors from long time series), MCMC methods are particularly valuable because:\n",
    "- They capture the full posterior from the long time series\n",
    "- The posterior can be used directly as a prior for the short series\n",
    "- Uncertainty propagates correctly through the transfer process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vangja20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
